import pandas as pd
import json
from os import listdir


directories = [
    "C:/Users/HP/Downloads/flight data/2016_original/2016",
    "C:/Users/HP/Downloads/flight data/2016_original/2017"
]

# List all flight data from 2016 to 2017
all_data = []


for directory in directories:
    
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.endswith(".csv"):
                file_path = os.path.join(root, file)
                df = pd.read_csv(file_path)
                all_data.append(df)


flight_data = pd.concat(all_data, ignore_index=True)

recommended_columns = ['FlightDate', 'Quarter', 'Year', 'Month', 'DayofMonth', 'DepTime', 'DepDel15', 'CRSDepTime', 'DepDelayMinutes', 'Origin', 'Dest', 'ArrTime', 'CRSArrTime', 'ArrDel15', 'ArrDelayMinutes']


flight_data = flight_data[recommended_columns]


#now let's do similar thing with the weather data



root_directory = "C:/Users/HP/Downloads/airport data"

all_weather_data = []


for root, dirs, files in os.walk(root_directory):
    for file in files:
        if file.endswith(".json"):
            file_path = os.path.join(root, file)
            with open(file_path, 'r') as f:
                data = json.load(f)
                weather_data = data.get('data', {}).get('weather', [])
                airport_name = data.get('data', {}).get('request', [{}])[0].get('query', '')
                for entry in weather_data:
                    hourly_data = entry.get('hourly', [])
                    weather_df = pd.DataFrame(hourly_data)
                    weather_df['airport'] = airport_name
                    weather_df['date'] = entry.get('date', '')
                    all_weather_data.append(weather_df)


weather_data = pd.concat(all_weather_data, ignore_index=True)


desired_columns = ['windspeedKmph', 'winddirDegree', 'weatherCode', 'precipMM', 
                   'visibility', 'pressure', 'cloudcover', 'DewPointF', 
                   'WindGustKmph', 'tempF', 'WindChillF', 'humidity', 
                   'time', 'date', 'airport']
weather_data = weather_data[desired_columns]


# Convert 'FlightDate' column to datetime format
flight_data_filtered['FlightDate'] = pd.to_datetime(flight_data_filtered['FlightDate'])

# Merging the  flight and weather data based on common
merged_data = pd.merge(flight_data_filtered, weather_data_filtered, how='inner', left_on=['FlightDate', 'Origin'], right_on=['date', 'airport_code'])


merged_data.drop(['date', 'airport_code'], axis=1, inplace=True)


merged_data.to_csv('merged_data.csv', index=False)

#but facing memory error in it so using chunks to remove memory error
#so another approach tried
selected_airports = ['ATL', 'CLT', 'DEN', 'DFW', 'EWR', 'IAH', 'JFK', 'LAS', 'LAX', 'MCO', 'MIA', 'ORD', 'PHX', 'SEA', 'SFO']
years = [2016, 2017]

# Filtering the flightdata
flight_data_filtered = flight_data[(flight_data['Origin'].isin(selected_airports)) & 
                                   (flight_data['Dest'].isin(selected_airports)) & 
                                   (flight_data['Year'].isin(years))]

# Convert 'FlightDate' column to datetime
flight_data_filtered['FlightDate'] = pd.to_datetime(flight_data_filtered['FlightDate'])



# Extracting airport codes
weather_data['airport_code'] = weather_data['airport'].str.split(',').str[0]

# Filtering of weather data similar to what we did before
weather_data_filtered = weather_data[(weather_data['airport_code'].isin(selected_airports)) &
                                     (weather_data['date'].dt.year.isin(years))]

# Defining chunk size
chunk_size = 10000  


merged_chunks = []

# Iterate over chunks of flight data to merge
for i in range(0, len(flight_data_filtered), chunk_size):
    flight_chunk = flight_data_filtered.iloc[i:i+chunk_size]
    merged_chunk = pd.merge(flight_chunk, weather_data_filtered, how='inner', left_on=['FlightDate', 'Origin'], right_on=['date', 'airport_code'])
    merged_chunks.append(merged_chunk)

merged_data = pd.concat(merged_chunks, ignore_index=True)

merged_data.drop(['date', 'airport_code'], axis=1, inplace=True)


merged_data.to_csv('merged_data.csv', index=False)







